{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials, SpotifyOAuth\n",
    "import spotipy.util as util\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from credential import secrets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save credential from .py field\n",
    "# The two first are essential for extracting general information\n",
    "SPOTIPY_CLIENT_ID=secrets.get('SPOTIPY_CLIENT_ID')\n",
    "SPOTIPY_CLIENT_SECRET=secrets.get('SPOTIPY_CLIENT_SECRET')\n",
    "#The indirect URI is used to extarct information from a personal account with more detail (ex: user_top_tracks)\n",
    "SPOTIPY_REDIRECT_URI =secrets.get('SPOTIPY_REDIRECT_URI')\n",
    "username =secrets.get('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bee50ef8746e41e293d2b3eaabc012dd'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPOTIPY_CLIENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_manager = SpotifyClientCredentials(client_id = SPOTIPY_CLIENT_ID, client_secret = SPOTIPY_CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=SPOTIPY_CLIENT_ID,\n",
    "                                               client_secret=SPOTIPY_CLIENT_SECRET,\n",
    "                                               redirect_uri=SPOTIPY_REDIRECT_URI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL you were redirected to: https://jperezllo.com/callback/?code=AQB7LJ1oDRFn3BZyxX5iQuzA_ikEBs8St6iFm7bSDYdTkgY4lAHSnda27muufzWhPMvUyvSk9rSnb_8yqhlPcLR3bl-VSQ0W7sc_Pl1tHMknvkUAakmUt52F31W3yEicSJGjbUdt_rE4a7nKwMQPLUF8MVIWfmNPl4mWxppSC1RJiLPk9AUazqRsPYTlXsF45Rc\n"
     ]
    }
   ],
   "source": [
    "# The scope is what determines the request we can execute. In this case the I'm using the \"user-top-read\" \n",
    "# because I want to extract the songs I've listened to the most\n",
    "scope = 'user-top-read'\n",
    "#Another peculiarity of this request is that it requires a token, unlike the general requests we can execute\n",
    "# with basic credentials\n",
    "token = util.prompt_for_user_token(username,scope,client_id=SPOTIPY_CLIENT_ID\n",
    "                           ,client_secret=SPOTIPY_CLIENT_SECRET\n",
    "                           ,redirect_uri=SPOTIPY_REDIRECT_URI)\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)\n",
    "results = sp.current_user_top_tracks()\n",
    "tracks = results['items']\n",
    "\n",
    "while results['next']:\n",
    "    results = sp.next(results)\n",
    "    tracks.extend(results['items'])\n",
    "\n",
    "my_top_songs = pd.DataFrame()\n",
    "my_top_songs['track'] = [tracks[item]['name'] for item in range(0, len(tracks))]\n",
    "my_top_songs['id'] = [tracks[item]['id'] for item in range(0, len(tracks))] \n",
    "my_top_songs['ranking'] = list(range(1,len(my_top_songs)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top_songs.to_csv(\"data\\\\csv\\\\my_top_songs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_0 = pd.read_json('data\\\\json\\\\StreamingHistory0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = pd.read_json('data\\\\json\\\\StreamingHistory1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_streaming_history = pd.concat([history_0, history_1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_streaming_history.to_csv('data\\\\csv\\\\my_streaming_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_queries = pd.read_json('data\\\\json\\\\SearchQueries.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\\\csv\\\\tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv('data\\\\csv\\\\track_images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all artists id on my JP playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/39086287/spotipy-how-to-read-more-than-100-tracks-from-a-playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(\"perezllo\",scope,client_id=SPOTIPY_CLIENT_ID\n",
    "                               ,client_secret=SPOTIPY_CLIENT_SECRET\n",
    "                               ,redirect_uri=SPOTIPY_REDIRECT_URI)\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)\n",
    "results = sp.current_user_playlists(limit=50)\n",
    "playlists = results['items']\n",
    "ignore_playlists = ['This Is RIOPY', '2022', 'Sons Of The East Radio',\n",
    "                'Life Is  Wonderful', 'Acoustic Chill', 'Acoustic Pop Hits','Discover Weekly',\n",
    "                    'Life Is Wonderful','Dance Music','Indie Folk Chill','Heart Beats','Disney']\n",
    "\n",
    "while results['next']:\n",
    "    results = sp.next(results)\n",
    "    playlists.extend(results['items'])\n",
    "    my_playlists = [playlist for playlist in my_playlists if playlist not in ignore_playlists]\n",
    "\n",
    "my_playlists_id = [playlists[item]['id'] for item in range(0, len(playlists))]\n",
    "my_playlists_name =[playlists[item]['name'] for item in range(0, len(playlists))]\n",
    "my_playlists = pd.DataFrame({\"playlist\":my_playlists_name, \"playlist_id\":my_playlists_id})\n",
    "my_playlists = my_playlists[~my_playlists['playlist'].isin(ignore_playlists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_playlists.to_csv(\"data\\\\csv\\\\my_playlists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_playlists(username):\n",
    "   # my_playlists = sp.user_playlists('perezllo')['items']\n",
    "   # playlist_id = []\n",
    "   # for number in range(0, len(my_playlists)):\n",
    "        #playlist_id[my_playlists[number]['name']] = my_playlists[number]['id']\n",
    "        #playlist_id.append(my_playlists[number]['id'])\n",
    "    #return playlist_id\n",
    "    \n",
    "scope = 'playlist-read-private'\n",
    "# Function to extract all my playlists\n",
    "def get_playlists(username):\n",
    "    token = util.prompt_for_user_token(username,scope,client_id=SPOTIPY_CLIENT_ID\n",
    "                               ,client_secret=SPOTIPY_CLIENT_SECRET\n",
    "                               ,redirect_uri=SPOTIPY_REDIRECT_URI)\n",
    "\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    results = sp.current_user_playlists(limit=50)\n",
    "    playlists = results['items']\n",
    "    #ignore_playlists = ['This Is RIOPY', '2022', 'Sons Of The East Radio',\n",
    "    #                'Life Is  Wonderful', 'Acoustic Chill', 'Acoustic Pop Hits','Discover Weekly',\n",
    "    #                    'Life Is Wonderful','Dance Music','Indie Folk Chill','Heart Beats','Disney']\n",
    "    \n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        playlists.extend(results['items'])\n",
    "        my_playlists = [playlist for playlist in my_playlists if playlist not in ignore_playlists]\n",
    "        \n",
    "    my_playlists_id = [playlists[item]['id'] for item in range(0, len(playlists))]\n",
    "    my_playlists_name =[playlists[item]['name'] for item in range(0, len(playlists))]\n",
    "    my_playlists = pd.DataFrame({\"playlist\":my_playlists_name, \"playlist_id\":my_playlists_id})\n",
    "    #my_playlists = my_playlists[~my_playlists['playlist'].isin(ignore_playlists)]\n",
    "    return my_playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once I have my playlsits and their ID I can extract the tracks id that comprise them\n",
    "def playlist_tracks(playlist_id):\n",
    "    #I first need to get the playlsit tracks using sp.playlist_tracks(playlist_id) which will return a dicitionary\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    #In the \"items\" key we have all the tracks stored, and that what needs to be used\n",
    "    tracks = results['items']\n",
    "    #I want to create a dicitonary with the name of the track as the key and its ID as the value to then create a DF\n",
    "    track_info = {}\n",
    "    #Spotipy has a limit of 20 results per request, but this can be solved by using the \"Next\" key inside the dicitionary.\n",
    "    # This will allow us to keep extarcting results until we have all of them\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    for item in range(0, len(tracks)):\n",
    "        track_info[tracks[item]['track']['name']]={\"id\":tracks[item]['track']['id']}\n",
    "    return track_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onec I have my playlsits and their ID I can extract the tracks id that comprise them\n",
    "def get_playlist_tracks(playlist_id):\n",
    "    #I first need to get the playlsit tracks using sp.playlist_tracks(playlist_id) which will return a dicitionary\n",
    "    results = sp.playlist_tracks(playlist_id)\n",
    "    #In the \"items\" key we have all the tracks stored, and that what needs to be used\n",
    "    tracks = results['items']\n",
    "    #I want to create a dicitonary with the name of the track as the key and its ID as the value to then create a DF\n",
    "    track_info = {}\n",
    "    #Spotipy has a limit of 20 results per request, but this can be solved by using the \"Next\" key inside the dicitionary.\n",
    "    # This will allow us to keep extarcting results until we have all of them\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "     #I also want to extract the audio characteristics of each song, information I can get using sp.audio_features(track_id)\n",
    "    #I have all the tracks stored in the tracks list and I can iterate through it to get what I need. \n",
    "    # I use a range in the for loop beacuse I need to iterate thorugh all items in the dicitionary\n",
    "    for item in range(0, len(tracks)):\n",
    "        #I extract the track_id\n",
    "        track_id = tracks[item]['track']['id']\n",
    "        #sp.audio_features will return a dicitonary with some unnecessary information than can be discarded\n",
    "        keys_to_remove =[\"type\", \"uri\", \"track_href\",\"analysis_url\", \"time_signature\",\"id\"]\n",
    "        #Applying sp.audio_features to each track\n",
    "        audio_features =  sp.audio_features(track_id)\n",
    "        audio_features = audio_features[0]\n",
    "        #Remove unnecessary fields \n",
    "        for key in keys_to_remove:\n",
    "            try: \n",
    "                audio_features.pop(key, None)\n",
    "            except:\n",
    "                pass\n",
    "        #Add track_name as the key and create another dicitonary where to store all the information, startin with the ID\n",
    "        track_info[tracks[item]['track']['name']] = {\"id\":track_id ,\"playlist_id\":playlist_id}\n",
    "        try:\n",
    "            #Add audio features to the dicitionary containing the information of each track\n",
    "            track_info[tracks[item]['track']['name']].update(audio_features)\n",
    "        except:\n",
    "            pass\n",
    "    return  track_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_track_info(username):\n",
    "    playlists = get_playlists(username)\n",
    "    full_tracks = {}\n",
    "    for playlist_id in playlists['playlist_id']: \n",
    "        full_tracks.update(get_playlist_tracks(playlist_id))\n",
    "    results = pd.DataFrame.from_dict(full_tracks, orient='index')\n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the URL you were redirected to: https://jperezllo.com/callback/?code=AQBXOqMG3uvDliPH0qU7OCWt1mf2D6jWjy4_JhDAVff8WH6kiHerPQrkGtR0ZP_jfVC0WROLag44ivqsU3xL3Ctwn1PRYtaRKVQ7UzeAztcibTgtnbFFn5bDl69HXajdZk4M0uWmrR8rX6GQ0n9VuPHLQzB9VACyYFc7oWWTMbxas0KbCWgSp5fak8bFD-ajxftOW8XBmgwhjQ\n"
     ]
    }
   ],
   "source": [
    "tracks = get_all_track_info(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "values_to_normalize = tracks['loudness']*-1\n",
    "values_to_normalize_2d = values_to_normalize.values.reshape(-1,1)\n",
    "normalized_column = scaler.fit_transform(values_to_normalize_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['tempo_normalized'] = normalized_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks['loudness_normalized'] = normalized_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_normalized = tracks.rename(columns={'index':'track'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_images = {}\n",
    "for track_id in tracks['id']:\n",
    "    try:\n",
    "        images = sp.track(track_id)['album']['images'][0]['url']\n",
    "        track_images[track_id] = images\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result = pd.merge(result_s,a[['playlist_id','playlist']],on='playlist_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_normalized.to_csv('data\\\\tracks_normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting artists information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The lat piece information I need for my analysis is related to the artists of my tracks\n",
    "#I'm going to create an empty dictionary using the defaultdict() class from the collections module.\n",
    "#This will help keeping all results and not overwrite exisiting ones because one track cna have more than one artist I want\n",
    "#to get all of them\n",
    "track_genres = defaultdict(list)\n",
    "#I start by using the 'id' column from my recently created dataframe\n",
    "for track_id in data['id']:\n",
    "    #We get the basic information from each artists involved with the track.\n",
    "    #Important! If a track has more that one artists involved the results will be returned in a list of dicitonaries\n",
    "    #so I need to use a for loop to iterate through the entire list\n",
    "    time.sleep(3)\n",
    "    track_details = sp.track(track_id)\n",
    "    artists = track_details['artists']\n",
    "   # try:\n",
    "   #     image = track_details['album']['images'][0]['url']\n",
    "   # except:\n",
    "       # pass\n",
    "    #Again, I use a range to make sure I iterate through alll items(artists) in the list\n",
    "    for artist in range(0, len(artists)):\n",
    "        #Extract the id \n",
    "        artist_id = artists[artist]['id']\n",
    "        artist_image = artists[artist][image][0][url]\n",
    "        #Extract all information froma artist using sp.artist(artist_id)\n",
    "        artist_info = sp.artist(artist_id)\n",
    "        #Fill track_genres dictionary with the artists information inside a dicitonary as the value and the track_id as the key\n",
    "        track_genres[track_id].append({'artist':artist_info['name'],\n",
    "                                            'artist_id': artist_id,\n",
    "                                            'genres':artist_info['genres'],\n",
    "                                            'track_id': track_id,\n",
    "                                            'popularity':artist_info['popularity']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_image = {}\n",
    "for artist_id in artists['artist_id'].unique():\n",
    "    try:\n",
    "        artist_img = sp.artist(artist_id)['images'][0]['url']\n",
    "    except: \n",
    "        pass\n",
    "    artists_image[artist_id] = artist_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists['image']=artists.artist_id.map(artists_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.to_csv('data\\\\csv\\\\artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mergeing playlists and imag_url for the Imgur step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.rename(columns={'track_id':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_streaming_history.rename(columns={'trackName':'track'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_streaming_history_agg = my_streaming_history.groupby(['track','artistName']).agg({'msPlayed':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_streaming_history_agg = my_streaming_history_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_playlists = tracks_normalized.merge(my_playlists, how ='left').merge(my_top_songs, how='left').merge(my_streaming_history_agg,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['This Is RIOPY', '2022', 'Sons Of The East Radio',\n",
    "                'Life Is  Wonderful', 'Acoustic Chill', 'Acoustic Pop Hits','Discover Weekly',\n",
    "                    'Life Is Wonderful','Dance Music','Indie Folk Chill','Heart Beats','Disney']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_playlists= data_playlists[~data_playlists.playlist.isin(exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = ['danceability','energy','key','mode','speechiness','acousticness','instrumentalness',\n",
    "                 'liveness','valence','tempo_normalized','loudness_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_unpivot = pd.melt(data_playlists, id_vars=['track','id','playlist_id','playlist'\n",
    "                                         ,'mode','key'],value_vars=audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_unpivot.to_csv(\"data\\\\csv\\\\tracks_unpivot_normalized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_images = pd.DataFrame(list(track_images.items()), columns =['id','image_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_images.to_csv('data\\\\track_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\\\tracks_unpivot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = pd.read_csv('data\\\\tracks_unpivot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_excel('data\\\\form.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining valid URL - Scraping Imgur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credential import imgur_credentials as imgur\n",
    "imgur_username = imgur['username']\n",
    "imgur_password = imgur['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pd.read_csv('data\\\\track_images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate my_streaming_history to obtain that total seconds listened to each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tracks = data_playlists[(~data_playlists.ranking.isnull()) & (data_playlists.playlist !='Gym')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tracks = top_tracks[['track','id','playlist','artistName','msPlayed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tracks['image'] = top_tracks.id.map(track_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to identify those songs that ar my top current songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_top_songs = data.merge(my_top_songs, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm going to create two rankings - most seconds listened and my current top songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My gym playlist does not contains many songs that I actually listen to, so I'm going to exclude them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_imgur_url(df):\n",
    "    #track_image = pd.DataFrame(columns=['track', 'image_url'])\n",
    "    #track_image['track'] = df.track\n",
    "    PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "    target_url = \"https://imgur.com\"\n",
    "    driver=webdriver.Chrome(PATH)\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    driver.get(target_url)\n",
    "    #Find sign in button and click on it\n",
    "    sign_in = driver.find_element(By.CLASS_NAME, 'Navbar-signin')\n",
    "    sign_in.click()\n",
    "\n",
    "    #Send user credentials (username and password) and click on SIGN IN\n",
    "    driver.find_element(By.XPATH, '/html/body/div[5]/div[3]/form/div[1]/input[1]').send_keys(imgur_username)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[5]/div[3]/form/div[1]/p/input').send_keys(imgur_password)\n",
    "    sign_in = driver.find_element(By.XPATH, '/html/body/div[5]/div[3]/form/div[2]/button').click()\n",
    "\n",
    "    #Open dropdown menu from my profile and enter the Images section\n",
    "    driver.find_element(By.XPATH, '/html/body/div/div/div[1]/div/div[1]/div[3]/div[5]/div/div[2]/div/div[1]/span[2]').click()\n",
    "    driver.find_element(By.XPATH, '/html/body/div/div/div[1]/div/div[1]/div[3]/div[5]/div/div[2]/div/div[2]/div/div[2]/a[4]').click()\n",
    "\n",
    "    #Upload every image_url on my dataset \n",
    "    for image_url in df['image']:\n",
    "        time.sleep(12)\n",
    "        driver.find_element(By.XPATH,'/html/body/div[7]/div[2]/div[1]/div[1]').click()\n",
    "        driver.find_element(By.XPATH, '/html/body/div[6]/div/span[1]/div/div/div[2]/div[3]/input').send_keys(image_url)\n",
    "    urls = []\n",
    "\n",
    "    #Extract new_url from imgur\n",
    "    for number in reversed(range(1,len(df['image'])+1)):\n",
    "        time.sleep(7)\n",
    "        urls.append(re.search(r'\\/\\/i.imgur.com\\/\\w*.jpg',driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div/div[5]/div[1]/div[1]/div[{number}]'.format(number=number)).get_attribute(\"style\")).group())\n",
    "    df['image'] = urls\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_listened_url = extract_imgur_url(top_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_listened_url.to_csv('most_listened_to_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_image.to_csv('top_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>『欲』</td>\n",
       "      <td>//i.imgur.com/2xxbNVkb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Katawaredoki</td>\n",
       "      <td>//i.imgur.com/eQonh9jb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>A Way of Life</td>\n",
       "      <td>//i.imgur.com/r0LsFTFb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Qué Bien</td>\n",
       "      <td>//i.imgur.com/vnK6CK5b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>ハーケン</td>\n",
       "      <td>//i.imgur.com/Exg1qJUb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             track                   image_url\n",
       "512            『欲』  //i.imgur.com/2xxbNVkb.jpg\n",
       "499   Katawaredoki  //i.imgur.com/eQonh9jb.jpg\n",
       "480  A Way of Life  //i.imgur.com/r0LsFTFb.jpg\n",
       "35        Qué Bien  //i.imgur.com/vnK6CK5b.jpg\n",
       "524           ハーケン  //i.imgur.com/Exg1qJUb.jpg"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credential import sql_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = sql_credentials['hostname']\n",
    "user_name = sql_credentials['username']\n",
    "password = sql_credentials['password']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = mysql.connector.connect(\n",
    "host=host_name,\n",
    "user=user_name,\n",
    "passwd=password)\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/spotify_project\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data\\\\tracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('data\\\\artists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_normalized = pd.read_csv('data\\\\tracks_unpivot_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25929"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_normalized.to_sql('audio_features_normalized',con=engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_top_songs.to_sql('top_songs',con=engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_images.to_sql('track_images', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returning names of related artiststs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Indie Folk Chill', 'Acoustic Pop Hits', \"Chillin'\",\n",
       "       'Chillout 2023', 'Acoustic Chill', 'Sons Of The East Radio',\n",
       "       'House', 'JP', '2022', 'This Is RIOPY', 'Life Is Wonderful',\n",
       "       'para cantar', 'Discover Weekly', 'Dance Music', 'Chill-up',\n",
       "       'Disney', 'OST', 'Gym'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.playlist.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_artists(artist_id):\n",
    "    results = sp.artist_related_artists(artist_id)\n",
    "    artists = results['artists']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "        artists_id = [item['track']['artists'][0]['id'] for item in tracks]\n",
    "    return artists_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_artists = sp.artist_related_artists('2hazSY4Ef3aB9ATXW7F5w3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_artists_id(artists_id_list):\n",
    "    # for artist_id in artist_id_list:\n",
    "    related_artists = []\n",
    "    related_artists_id = []\n",
    "    \n",
    "    for artist_id in artists_id_list: \n",
    "        related_artists.append(sp.artist_related_artists(artist_id))\n",
    "    \n",
    "    for n_1 in range(0, len(related_artists)):\n",
    "        for n_2 in range(0, len(related_artists[n_1]['artists'])):\n",
    "            if related_artists[n_1]['artists'][n_2]['name'] not in related_artists_id: \n",
    "                related_artists_id.append(related_artists[n_1]['artists'][n_2]['id'])\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "            \n",
    "    return related_artists_id\n",
    "        \n",
    "  #  return len(related_artists) # related_artists_id\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_artists_id = related_artists_id(artist_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
